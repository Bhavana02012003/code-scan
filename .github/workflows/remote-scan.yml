name: Remote Code Scan

on:
  repository_dispatch:
    types: [run-scan]

permissions:
  contents: write
  actions: read

jobs:
  scan:
    runs-on: ubuntu-latest
    env:
      REPO_URL:  ${{ github.event.client_payload.repo_url }}
      OWNER:     ${{ github.event.client_payload.owner }}
      REPO:      ${{ github.event.client_payload.repo }}
      BRANCH:    ${{ github.event.client_payload.branch || 'main' }}
      TECH:      ${{ github.event.client_payload.technology }}
      CORR:      ${{ github.event.client_payload.correlation_id }}
      REPORT_PATH: ${{ github.event.client_payload.report_path }}

    steps:
      - name: Checkout orchestrator repo
        uses: actions/checkout@v4

      - name: Show inputs
        run: |
          echo "TECH=$TECH"
          echo "REPO_URL=$REPO_URL"
          echo "REPORT_PATH=$REPORT_PATH"

      # Detect PAT
      - name: Detect GH_PAT
        id: has-pat
        shell: bash
        env:
          GH_PAT: ${{ secrets.GH_PAT }}
        run: |
          if [ -n "${GH_PAT}" ]; then
            echo "USE_PAT=true" >> "$GITHUB_ENV"
          else
            echo "USE_PAT=false" >> "$GITHUB_ENV"
          fi

      - name: Clone target repository (public)
        if: ${{ env.USE_PAT == 'false' }}
        run: git clone --depth 1 --branch "$BRANCH" "$REPO_URL" target

      - name: Clone target repository (private via GH_PAT)
        if: ${{ env.USE_PAT == 'true' }}
        run: |
          URL_AUTH="https://${{ secrets.GH_PAT }}@${REPO_URL#https://}"
          git clone --depth 1 --branch "$BRANCH" "$URL_AUTH" target

      # ---- Overlay config pack ----
      - name: Overlay config pack
        run: |
          TECH_LOWER=$(echo "$TECH" | tr '[:upper:]' '[:lower:]')
          SRC="configs/$TECH_LOWER"
          if [ -d "$SRC" ]; then
            rsync -a --exclude 'tsconfig.template.json' "$SRC"/ target/
            if [ -f "$SRC/tsconfig.template.json" ] && git -C target ls-files '*.ts' '*.tsx' | grep -q .; then
              cp "$SRC/tsconfig.template.json" target/tsconfig.json
            fi
            echo "Overlay complete."
          else
            echo "No overlay for $TECH (optional)."
          fi

      # ---- Setup common tooling ----
      - uses: actions/setup-node@v4
        with:
          node-version: 20
      - uses: actions/setup-python@v5
        with:
          python-version: '3.x'
      - uses: actions/setup-dotnet@v4
        if: ${{ env.TECH == 'DotNet' }}
        with:
          dotnet-version: '8.0.x'

      # ============ SALESFORCE (PMD) ============
      - name: Salesforce • Setup Java
        if: ${{ env.TECH == 'Salesforce' }}
        uses: actions/setup-java@v4
        with:
          distribution: 'temurin'
          java-version: '17'

      - name: Salesforce • Download PMD
        if: ${{ env.TECH == 'Salesforce' }}
        run: |
          set -e
          PMD_VER=6.55.0
          curl -L "https://github.com/pmd/pmd/releases/download/pmd_releases/${PMD_VER}/pmd-bin-${PMD_VER}.zip" -o pmd.zip
          sudo apt-get update && sudo apt-get install -y unzip
          unzip -q pmd.zip
          mv "pmd-bin-${PMD_VER}" pmd
          ./pmd/bin/run.sh pmd -version

      - name: Salesforce • Full repo scan (filelist) → CSV
        if: ${{ env.TECH == 'Salesforce' }}
        working-directory: target
        run: |
          set -e
          mkdir -p ../out
          # Build a filelist with every Apex file in the repo, regardless of folder layout
          # (handles sfdx, mdapi, multi-package, etc.)
          find . -type f \( -name "*.cls" -o -name "*.trigger" \) > ../out/apex-files.txt || true

          COUNT=$(wc -l < ../out/apex-files.txt || echo 0)
          echo "Discovered Apex files: $COUNT"
          if [ "$COUNT" -eq 0 ]; then
            echo "Problem,Package,File,Priority,Line,Description,Rule set,Rule" > ../out/pmd.csv
            exit 0
          fi

          # Use a conservative ruleset that always exists in PMD:
          # rulesets/apex/quickstart.xml
          ../../pmd/bin/run.sh pmd \
            -language apex \
            -filelist ../out/apex-files.txt \
            -f csv \
            -R rulesets/apex/quickstart.xml \
            > ../out/pmd.csv || true

          # Ensure file exists even if PMD printed nothing
          if [ ! -s ../out/pmd.csv ]; then
            echo "Problem,Package,File,Priority,Line,Description,Rule set,Rule" > ../out/pmd.csv
          fi


      # ============ .NET ============
      - name: .NET • Install SDK
        if: ${{ env.TECH == 'DotNet' }}
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: '8.0.x'

      - name: .NET • Find project/solution
        if: ${{ env.TECH == 'DotNet' }}
        id: dotnet-target
        working-directory: target
        run: |
          set -e
          T=$( (ls *.sln 2>/dev/null || true; ls *.csproj 2>/dev/null || true) | head -n 1 )
          if [ -z "$T" ]; then T=$(git ls-files "*.sln" "*.csproj" | head -n 1); fi
          echo "TARGET=$T" >> $GITHUB_ENV
          echo "Using target: $T"

      - name: .NET • Restore
        if: ${{ env.TECH == 'DotNet' }}
        working-directory: target
        run: |
          set -e
          dotnet restore "$TARGET" || true

      - name: .NET • dotnet format (JSON report)
        if: ${{ env.TECH == 'DotNet' }}
        working-directory: target
        run: |
          mkdir -p ../out
          dotnet tool install -g dotnet-format
          export PATH="$HOME/.dotnet/tools:$PATH"
          dotnet format "$TARGET" --verify-no-changes --report ../out/dotnet-format.json --report-format json || true

      - name: .NET • Build (enable analyzers) → capture warnings
        if: ${{ env.TECH == 'DotNet' }}
        working-directory: target
        run: |
          # Enable Microsoft/Roslyn analyzers strongly so you actually get diagnostics
          dotnet build "$TARGET" \
            /warnaserror- \
            -p:EnableNETAnalyzers=true \
            -p:AnalysisLevel=latest \
            -p:TreatWarningsAsErrors=false \
            -nologo -v:minimal \
            > ../out/build_output.txt 2>&1 || true

      - name: .NET • Dependency vulnerabilities (optional)
        if: ${{ env.TECH == 'DotNet' }}
        working-directory: target
        run: |
          dotnet list "$TARGET" package --vulnerable --include-transitive --format json > ../out/dotnet-packages.json || echo '{}' > ../out/dotnet-packages.json

      # ============ PYTHON ============
      - name: Python • Install linters
        if: ${{ env.TECH == 'Python' }}
        run: |
          python -m pip install --upgrade pip
          pip install bandit pylint flake8 flake8-json
      - name: Python • Scan
        if: ${{ env.TECH == 'Python' }}
        working-directory: target
        run: |
          mkdir -p ../out
          bandit -r . -f json -o ../out/bandit.json || true
          find . -name "*.py" > ../out/files.txt
          if [ -s ../out/files.txt ]; then
            pylint $(cat ../out/files.txt) --output-format=json > ../out/pylint.json || true
          else
            echo "[]" > ../out/pylint.json
          fi
          flake8 . --format=json --output-file=../out/flake8.json || true

      # ============ REACT ============
      - name: React • Install deps
        if: ${{ env.TECH == 'React' }}
        working-directory: target
        run: npm ci || npm install
      - name: React • ESLint/tsc/audit
        if: ${{ env.TECH == 'React' }}
        working-directory: target
        run: |
          mkdir -p ../out
          npx eslint . --ext .js,.jsx,.ts,.tsx -f json -o ../out/eslint.json || true
          if find . -name "tsconfig*.json" -type f | grep -q .; then
            npx tsc --noEmit > ../out/tsc-output.txt 2>&1 || true
          fi
          npm audit --json > ../out/audit.json || true

      # ============ Normalize ============
      - name: Normalize to CSV
        run: |
          python - << 'PY'
          import os, json, csv, re
          rows=[["Tool","File","Line","Severity","Rule","Message"]]
          out="out/normalized.csv"
          os.makedirs("out", exist_ok=True)
          def add(tool,f,l,s,r,m): rows.append([tool,f or "",str(l or ""),str(s or ""),str(r or ""), (m or "").replace("\n"," ").strip()])
          # Salesforce PMD
          p="out/pmd.csv"
          if os.path.exists(p) and os.path.getsize(p)>0:
              with open(p,newline="",encoding="utf-8",errors="ignore") as f:
                  r=csv.DictReader(f)
                  for d in r:
                      add("PMD", d.get("File"), d.get("Line"), d.get("Priority"), d.get("Rule"), d.get("Description"))
          # ---------- .NET dotnet-format ----------
          p = "out/dotnet-format.json"
          if os.path.exists(p) and os.path.getsize(p) > 0:
              try:
                  data = json.load(open(p, encoding="utf-8", errors="ignore"))
              except Exception as e:
                  data = None
                  print("Failed to parse dotnet-format.json:", e)

              def field(d, *names, default=None):
                  for n in names:
                      if isinstance(d, dict) and n in d:
                          return d.get(n)
                  return default

              def add_diag(v):
                  add(".NET(format)",
                      field(v, "FilePath", "file", "Document"),
                      field(v, "LineNumber", "line", "StartLine"),
                      field(v, "Severity", "severity", "Category"),
                      field(v, "RuleId", "id", "DiagnosticId", "rule"),
                      field(v, "Message", "message", "Title"))

              if isinstance(data, dict):
                  diags = data.get("Diagnostics") or data.get("violations") or data.get("results") or []
                  for v in diags:
                      add_diag(v)
              elif isinstance(data, list):
                  for v in data:
                      add_diag(v)

          # ---------- .NET build warnings/errors (compiler + analyzers) ----------
          p = "out/build_output.txt"
          if os.path.exists(p) and os.path.getsize(p) > 0:
              rx = re.compile(r'(.+\.cs)\((\d+),\d+\): (warning|error) (\w+): (.+?) \[')
              for line in open(p, encoding='utf-8', errors='ignore'):
                  m = rx.search(line)
                  if m:
                      file, line_no, sev, rule, msg = m.groups()
                      add(".NET(build)", file, line_no, sev.capitalize(), rule, msg)

          # ---------- .NET dependency vulnerabilities ----------
          p = "out/dotnet-packages.json"
          if os.path.exists(p) and os.path.getsize(p) > 0:
              try:
                  data = json.load(open(p, encoding="utf-8", errors="ignore"))
                  # dotnet list package JSON shape: { "projects": [ { "frameworks":[{"topLevelPackages":[...], "transitivePackages":[...]}] } ] }
                  projs = data.get("projects") or []
                  for proj in projs:
                      for fw in proj.get("frameworks", []):
                          for section in ("topLevelPackages", "transitivePackages"):
                              for pkg in fw.get(section, []):
                                  if pkg.get("vulnerabilities"):
                                      for v in pkg["vulnerabilities"]:
                                          add(".NET(pkg)",
                                              f'{pkg.get("id")}@{pkg.get("requestedVersion") or pkg.get("resolvedVersion")}',
                                              "",
                                              v.get("severity"),
                                              v.get("advisoryUrl") or v.get("advisoryIds") or "",
                                              v.get("description") or "Dependency vulnerability")
              except Exception as e:
                  print("Failed to parse dotnet-packages.json:", e)

          # Python
          for tool,file in [("Bandit","out/bandit.json"),("Pylint","out/pylint.json")]:
              if os.path.exists(file):
                  data=json.load(open(file,encoding="utf-8"))
                  if tool=="Bandit":
                      for r in data.get("results",[]): add("Bandit",r.get("filename"),r.get("line_number"),r.get("issue_severity"),r.get("test_id"),r.get("issue_text"))
                  if tool=="Pylint":
                      for it in data: add("Pylint",it.get("path"),it.get("line"),it.get("type"),it.get("message-id"),it.get("message"))
          p="out/flake8.json"
          if os.path.exists(p):
              data=json.load(open(p,encoding="utf-8"))
              for file,issues in data.items():
                  for i in issues: add("Flake8",file,i.get("line_number"),i.get("code"),i.get("code"),i.get("text"))
          # React
          p="out/eslint.json"
          if os.path.exists(p):
              data=json.load(open(p,encoding="utf-8"))
              if isinstance(data,dict): data=[data]
              for f in data:
                  for m in f.get("messages",[]): add("ESLint",f.get("filePath"),m.get("line"),"Error" if m.get("severity")==2 else "Warning",m.get("ruleId"),m.get("message"))
          p="out/tsc-output.txt"
          if os.path.exists(p):
              rx=re.compile(r"(.+\.(?:ts|tsx|js|jsx))\((\d+),\d+\): (error|warning) (TS\d+): (.+)")
              for line in open(p,encoding="utf-8",errors="ignore"):
                  m=rx.search(line)
                  if m: file,l,sev,code,msg=m.groups(); add("tsc",file,l,sev.capitalize(),code,msg)
          p="out/audit.json"
          if os.path.exists(p):
              data=json.load(open(p,encoding="utf-8"))
              for pkg,v in (data.get("vulnerabilities") or {}).items():
                  for item in v.get("via",[]):
                      if isinstance(item,dict): add("npm-audit",pkg,"",v.get("severity"),item.get("name"),item.get("title"))
          with open(out,"w",newline="",encoding="utf-8") as f: csv.writer(f).writerows(rows)
          print("Wrote", out, "rows:", len(rows)-1)
          PY

      - name: Commit report into orchestrator
        run: |
          mkdir -p "$(dirname "$REPORT_PATH")"
          cp out/normalized.csv "$REPORT_PATH"
          git config user.name "orchestrator-bot"
          git config user.email "orchestrator@example.com"
          git add "$REPORT_PATH"
          git commit -m "Scan report: $OWNER/$REPO ($TECH) • $CORR" || echo "Nothing to commit"
          git push

      - uses: actions/upload-artifact@v4
        with:
          name: report-${{ env.CORR }}
          path: out/normalized.csv
