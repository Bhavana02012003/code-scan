name: Remote Code Scan

on:
  repository_dispatch:
    types: [run-scan]

permissions:
  contents: write
  actions: read

jobs:
  scan:
    runs-on: ubuntu-latest
    env:
      REPO_URL:  ${{ github.event.client_payload.repo_url }}
      OWNER:     ${{ github.event.client_payload.owner }}
      REPO:      ${{ github.event.client_payload.repo }}
      BRANCH:    ${{ github.event.client_payload.branch || 'main' }}
      TECH:      ${{ github.event.client_payload.technology }}
      CORR:      ${{ github.event.client_payload.correlation_id }}
      REPORT_PATH: ${{ github.event.client_payload.report_path }}

    steps:
      - name: Checkout orchestrator repo
        uses: actions/checkout@v4

      - name: Show inputs
        run: |
          echo "TECH=$TECH"
          echo "REPO_URL=$REPO_URL"
          echo "OWNER=$OWNER"
          echo "REPO=$REPO"
          echo "BRANCH=$BRANCH"
          echo "REPORT_PATH=$REPORT_PATH"

      - name: Checkout orchestrator repo
        uses: actions/checkout@v4

      - name: Get installation ID dynamically
        id: get_installation
        run: |
          OWNER=${{ env.OWNER }}
          INSTALL_ID=$(curl -s -H "Authorization: Bearer ${{ secrets.GH_APP_PRIVATE_KEY }}" \
                          -H "Accept: application/vnd.github+json" \
                          https://api.github.com/app/installations \
                        | jq -r ".[] | select(.account.login==\"$OWNER\") | .id")
          echo "installation_id=$INSTALL_ID" >> $GITHUB_OUTPUT

      - name: Generate GitHub App token
        id: generate_token
        uses: tibdex/github-app-token@v2
        with:
          app_id: ${{ secrets.GH_APP_ID }}
          private_key: ${{ secrets.GH_APP_PRIVATE_KEY }}
          installation_retrieval_mode: id
          installation_retrieval_payload: ${{ steps.get_installation.outputs.installation_id }}


      - name: Debug repo access
        run: |
          TOKEN=${{ steps.generate_token.outputs.token }}
          OWNER=naresh-art
          REPO=TestingGitActions
          curl -i -H "Authorization: Bearer $TOKEN" \
              -H "Accept: application/vnd.github+json" \
              https://api.github.com/repos/$OWNER/$REPO



      - name: Test App token permissions
        run: |
          TOKEN=${{ steps.generate_token.outputs.token }}
          curl -H "Authorization: Bearer $TOKEN" \
              -H "Accept: application/vnd.github+json" \
              https://api.github.com/repos/naresh-art/TestingGitActions

      
      # =========================================================
      # === Clone target repo (public OR private via GitHub App)
      # =========================================================
      - name: Clone target repository
        run: |
          TOKEN=${{ steps.generate_token.outputs.token }}
          # Ensure proper URL with x-access-token
          AUTH_URL="https://x-access-token:${TOKEN}@github.com/${OWNER}/${REPO}.git"
          echo "ðŸ” Cloning with App token: $AUTH_URL"
          git clone --depth 1 --branch "$BRANCH" "$AUTH_URL" target
      # ---- Overlay config pack (optional per-tech files) ----
      - name: Overlay config pack
        run: |
          TECH_LOWER=$(echo "$TECH" | tr '[:upper:]' '[:lower:]')
          SRC="configs/$TECH_LOWER"
          if [ -d "$SRC" ]; then
            rsync -a --exclude 'tsconfig.template.json' "$SRC"/ target/
            if [ -f "$SRC/tsconfig.template.json" ] && git -C target ls-files '*.ts' '*.tsx' | grep -q .; then
              cp "$SRC/tsconfig.template.json" target/tsconfig.json
            fi
            echo "Overlay complete."
          else
            echo "No overlay for $TECH (optional)."
          fi

      # ---- Common toolchains ----
      - uses: actions/setup-node@v4
        with:
          node-version: 20
      - uses: actions/setup-python@v5
        with:
          python-version: '3.x'
      - uses: actions/setup-dotnet@v4
        if: ${{ env.TECH == 'DotNet' }}
        with:
          dotnet-version: '8.0.x'

      # =========================================================
      # ===================  SALESFORCE (PMD)  ==================
      # =========================================================
      - name: Salesforce â€¢ Setup Java
        if: ${{ env.TECH == 'Salesforce' }}
        uses: actions/setup-java@v4
        with:
          distribution: 'temurin'
          java-version: '17'

      - name: Salesforce â€¢ Download PMD 6.x
        if: ${{ env.TECH == 'Salesforce' }}
        run: |
          set -e
          PMD_VER=6.55.0
          curl -L "https://github.com/pmd/pmd/releases/download/pmd_releases/${PMD_VER}/pmd-bin-${PMD_VER}.zip" -o pmd.zip
          sudo apt-get update && sudo apt-get install -y unzip
          unzip -q pmd.zip
          mv "pmd-bin-${PMD_VER}" pmd
          chmod +x pmd/bin/run.sh

      - name: Salesforce â€¢ Full scan with PMD â†’ CSV
        if: ${{ env.TECH == 'Salesforce' }}
        working-directory: target
        run: |
          set -e
          mkdir -p ../out
          FA=$(find . -type d -name "force-app" | head -n 1); [ -z "$FA" ] && FA="."
          ../pmd/bin/run.sh pmd -d "$FA" -f csv \
            -R category/apex/bestpractices.xml,category/apex/design.xml,category/apex/errorprone.xml,category/apex/performance.xml,category/apex/security.xml \
            > ../out/pmd.csv || true
          [ -s ../out/pmd.csv ] || echo "Problem,Package,File,Priority,Line,Description,Rule set,Rule" > ../out/pmd.csv

      # =========================================================
      # ========================  JAVA  =========================
      # =========================================================
      - name: Java â€¢ Setup JDK
        if: ${{ env.TECH == 'Java' }}
        uses: actions/setup-java@v4
        with:
          distribution: 'temurin'
          java-version: '17'

      # PMD for Java source
      - name: Java â€¢ Download PMD 6.x
        if: ${{ env.TECH == 'Java' }}
        run: |
          set -e
          PMD_VER=6.55.0
          curl -L "https://github.com/pmd/pmd/releases/download/pmd_releases/${PMD_VER}/pmd-bin-${PMD_VER}.zip" -o pmd-java.zip
          sudo apt-get update && sudo apt-get install -y unzip
          unzip -q pmd-java.zip
          mv "pmd-bin-${PMD_VER}" pmd_java
          chmod +x pmd_java/bin/run.sh

      - name: Java â€¢ PMD source scan â†’ CSV
        if: ${{ env.TECH == 'Java' }}
        working-directory: target
        run: |
          set -e
          mkdir -p ../out
          ../pmd_java/bin/run.sh pmd -d "." -f csv \
            -R category/java/bestpractices.xml,category/java/design.xml,category/java/errorprone.xml,category/java/performance.xml,category/java/security.xml,category/java/codestyle.xml,category/java/multithreading.xml \
            > ../out/pmd_java.csv || true
          [ -s ../out/pmd_java.csv ] || echo "Problem,Package,File,Priority,Line,Description,Rule set,Rule" > ../out/pmd_java.csv

      # OWASP Dependency-Check (CLI) for Java dep (works with Maven/Gradle or plain libs)
      - name: Java â€¢ OWASP Dependency-Check (CLI)
        if: ${{ env.TECH == 'Java' }}
        working-directory: target
        run: |
          set -e
          mkdir -p ../out
          DC_VER=9.0.9
          curl -L "https://github.com/jeremylong/DependencyCheck/releases/download/v${DC_VER}/dependency-check-${DC_VER}-release.zip" -o dc.zip
          unzip -q dc.zip
          mv dependency-check bin_dc
          # Use NVD (default). The first run may download data; allow failures to not break the job.
          ./bin_dc/bin/dependency-check.sh --scan "." --format JSON --out ../out --project "$REPO" || true
          # Normalize output file name
          JSON=$(ls ../out/*.json 2>/dev/null | head -n1 || true)
          if [ -n "$JSON" ] && [ "$JSON" != "../out/dependency-check.json" ]; then
            mv "$JSON" ../out/dependency-check.json
          fi
          [ -f ../out/dependency-check.json ] || echo "{}" > ../out/dependency-check.json

      # =========================================================
      # ========================= .NET ==========================
      # =========================================================
      - name: .NET â€¢ Restore and scan (format + analyzers + vulns)
        if: ${{ env.TECH == 'DotNet' }}
        working-directory: target
        run: |
          set -e
          mkdir -p ../out
          dotnet tool install -g dotnet-format
          export PATH="$HOME/.dotnet/tools:$PATH"
          TARGET=$( (ls *.sln 2>/dev/null || true; ls *.csproj 2>/dev/null || true) | head -n 1 )
          if [ -z "$TARGET" ]; then TARGET=$(git ls-files "*.sln" "*.csproj" | head -n 1); fi
          if [ -z "$TARGET" ]; then echo "No .sln or .csproj found"; echo "[]" > ../out/dotnet-format.json; : > ../out/build_output.txt; echo "{}" > ../out/dotnet-packages.json; exit 0; fi
          echo "Using target: $TARGET"
          dotnet restore "$TARGET" || true
          dotnet format "$TARGET" --verify-no-changes --report ../out/dotnet-format.json --report-format json || true
          dotnet build "$TARGET" -p:EnableNETAnalyzers=true -p:AnalysisLevel=latest --no-incremental -v:normal > ../out/build_output.txt || true
          dotnet list "$TARGET" package --vulnerable --include-transitive --format json > ../out/dotnet-packages.json || echo "{}" > ../out/dotnet-packages.json

      # =========================================================
      # ======================== PYTHON =========================
      # =========================================================
      - name: Python â€¢ Install linters
        if: ${{ env.TECH == 'Python' }}
        run: |
          python -m pip install --upgrade pip
          pip install bandit pylint flake8 flake8-json
      - name: Python â€¢ Scan
        if: ${{ env.TECH == 'Python' }}
        working-directory: target
        run: |
          mkdir -p ../out
          bandit -r . -f json -o ../out/bandit.json || true
          find . -name "*.py" > ../out/files.txt
          if [ -s ../out/files.txt ]; then
            pylint $(cat ../out/files.txt) --output-format=json > ../out/pylint.json || true
          else
            echo "[]" > ../out/pylint.json
          fi
          flake8 . --format=json --output-file=../out/flake8.json || true

      # =========================================================
      # ========================= REACT =========================
      # =========================================================
      - name: React â€¢ Install deps
        if: ${{ env.TECH == 'React' }}
        working-directory: target
        run: npm ci || npm install
      - name: React â€¢ ESLint/tsc/audit
        if: ${{ env.TECH == 'React' }}
        working-directory: target
        run: |
          mkdir -p ../out
          npx eslint . --ext .js,.jsx,.ts,.tsx -f json -o ../out/eslint.json || true
          if find . -name "tsconfig*.json" -type f | grep -q .; then
            npx tsc --noEmit > ../out/tsc-output.txt 2>&1 || true
          fi
          npm audit --json > ../out/audit.json || true

      # =========================================================
      # ===================== Normalize â†’ CSV ===================
      # =========================================================
      - name: Normalize to CSV
        run: |
          python - << 'PY'
          import os, json, csv, re
          rows=[["Tool","File","Line","Severity","Rule","Message"]]
          out="out/normalized.csv"
          os.makedirs("out", exist_ok=True)
          def add(tool,f,l,s,r,m): rows.append([tool,f or "",str(l or ""),str(s or ""),str(r or ""), (m or "").replace("\n"," ").strip()])

          # Salesforce PMD (Apex)
          p="out/pmd.csv"
          if os.path.exists(p) and os.path.getsize(p)>0:
              import csv as _csv
              with open(p,newline="",encoding="utf-8",errors="ignore") as f:
                  r=_csv.DictReader(f)
                  for d in r: add("PMD(Apex)", d.get("File"), d.get("Line"), d.get("Priority"), d.get("Rule"), d.get("Description"))

          # Java PMD
          p="out/pmd_java.csv"
          if os.path.exists(p) and os.path.getsize(p)>0:
              import csv as _csv
              with open(p,newline="",encoding="utf-8",errors="ignore") as f:
                  r=_csv.DictReader(f)
                  for d in r: add("PMD(Java)", d.get("File"), d.get("Line"), d.get("Priority"), d.get("Rule"), d.get("Description"))

          # Java Dependency-Check
          p="out/dependency-check.json"
          if os.path.exists(p) and os.path.getsize(p)>0:
              try:
                  data=json.load(open(p,encoding="utf-8"))
                  for dep in data.get("dependencies",[]) or []:
                      file = dep.get("fileName") or dep.get("filePath")
                      for v in dep.get("vulnerabilities",[]) or []:
                          sev=(v.get("severity") or "").capitalize()
                          rule=v.get("name") or ",".join(v.get("cwes",[]) or [])
                          msg=v.get("description") or v.get("title") or "Dependency vulnerability"
                          add("DepCheck(Java)", file, "", sev, rule, msg)
              except Exception as e:
                  print("DepCheck parse error:", e)

          # .NET dotnet-format
          p="out/dotnet-format.json"
          if os.path.exists(p) and os.path.getsize(p)>0:
              try: data=json.load(open(p,encoding="utf-8"))
              except Exception as e: data=None; print("dotnet-format parse error:", e)
              def field(d,*names,default=None):
                  for n in names:
                      if isinstance(d,dict) and n in d: return d.get(n)
                  return default
              def add_diag(v):
                  add(".NET(format)",
                      field(v,"FilePath","file","Document"),
                      field(v,"LineNumber","line","StartLine"),
                      field(v,"Severity","severity","Category"),
                      field(v,"RuleId","id","DiagnosticId","rule"),
                      field(v,"Message","message","Title"))
              if isinstance(data,dict):
                  for v in (data.get("Diagnostics") or data.get("violations") or data.get("results") or []): add_diag(v)
              elif isinstance(data,list):
                  for v in data: add_diag(v)

          # .NET build (compiler/analyzers)
          p="out/build_output.txt"
          if os.path.exists(p) and os.path.getsize(p)>0:
              rx=re.compile(r'(.+\.cs)\((\d+),\d+\): (warning|error) (\w+): (.+?) \[')
              for line in open(p,encoding="utf-8",errors="ignore"):
                  m=rx.search(line)
                  if m:
                      file,l,sev,rule,msg=m.groups()
                      add(".NET(build)", file, l, sev.capitalize(), rule, msg)

          # .NET NuGet vulns
          p="out/dotnet-packages.json"
          if os.path.exists(p) and os.path.getsize(p)>0:
              try:
                  data=json.load(open(p,encoding="utf-8"))
                  for proj in data.get("projects", []):
                      for fw in proj.get("frameworks", []):
                          for section in ("topLevelPackages","transitivePackages"):
                              for pkg in fw.get(section, []) or []:
                                  for v in (pkg.get("vulnerabilities") or []):
                                      sev=v.get("severity")
                                      rule=v.get("advisoryUrl") or ",".join(v.get("advisoryIds") or [])
                                      msg=v.get("description") or "NuGet dependency vulnerability"
                                      add(".NET(pkg)", f'{pkg.get("id")}@{pkg.get("requestedVersion") or pkg.get("resolvedVersion")}', "", sev, rule, msg)
              except Exception as e:
                  print("dotnet-packages parse error:", e)

          # Python
          p="out/bandit.json"
          if os.path.exists(p) and os.path.getsize(p)>0:
              data=json.load(open(p,encoding="utf-8"))
              for r in data.get("results",[]): add("Bandit",r.get("filename"),r.get("line_number"),r.get("issue_severity"),r.get("test_id"),r.get("issue_text"))
          p="out/pylint.json"
          if os.path.exists(p) and os.path.getsize(p)>0:
              data=json.load(open(p,encoding="utf-8"))
              if isinstance(data,list):
                  for it in data:
                      sev=(it.get("type") or "").capitalize()
                      add("Pylint", it.get("path"), it.get("line"), sev, it.get("message-id"), it.get("message"))
          p="out/flake8.json"
          if os.path.exists(p) and os.path.getsize(p)>0:
              data=json.load(open(p,encoding="utf-8"))
              for file,issues in data.items():
                  for i in issues: add("Flake8", file, i.get("line_number"), i.get("code"), i.get("code"), i.get("text"))

          # React
          p="out/eslint.json"
          if os.path.exists(p) and os.path.getsize(p)>0:
              data=json.load(open(p,encoding="utf-8"))
              if isinstance(data,dict): data=[data]
              for f in data:
                  fn=f.get("filePath")
                  for m in f.get("messages",[]):
                      sev="Error" if m.get("severity")==2 else "Warning"
                      add("ESLint", fn, m.get("line"), sev, m.get("ruleId"), m.get("message"))
          p="out/tsc-output.txt"
          if os.path.exists(p) and os.path.getsize(p)>0:
              rx=re.compile(r"(.+\.(?:ts|tsx|js|jsx))\((\d+),\d+\): (error|warning) (TS\d+): (.+)")
              for line in open(p,encoding="utf-8",errors="ignore"):
                  m=rx.search(line)
                  if m:
                      file,l,sev,code,msg=m.groups()
                      add("tsc", file, l, sev.capitalize(), code, msg)
          p="out/audit.json"
          if os.path.exists(p) and os.path.getsize(p)>0:
              data=json.load(open(p,encoding="utf-8"))
              for pkg,v in (data.get("vulnerabilities") or {}).items():
                  for item in v.get("via",[]):
                      if isinstance(item,dict):
                          add("npm-audit", pkg, "", v.get("severity"), item.get("name") or item.get("title"), item.get("title"))

          with open(out,"w",newline="",encoding="utf-8") as f:
              csv.writer(f).writerows(rows)
          print("Wrote", out, "rows:", len(rows)-1)
          PY

      - name: Commit report into orchestrator
        run: |
          mkdir -p "$(dirname "$REPORT_PATH")"
          cp out/normalized.csv "$REPORT_PATH"
          git config user.name "orchestrator-bot"
          git config user.email "orchestrator@example.com"
          git add "$REPORT_PATH"
          git commit -m "Scan report: $OWNER/$REPO ($TECH) â€¢ $CORR" || echo "Nothing to commit"
          git push

      - uses: actions/upload-artifact@v4
        with:
          name: report-${{ env.CORR }}
          path: out/normalized.csv
