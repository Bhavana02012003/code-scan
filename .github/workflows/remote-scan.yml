name: Remote Code Scan

on:
  repository_dispatch:
    types: [run-scan]

permissions:
  contents: write   # we commit normalized.csv back into this repo
  actions: read

jobs:
  scan:
    runs-on: ubuntu-latest

    env:
      # Payload from your LWC -> Apex -> repository_dispatch
      REPO_URL:   ${{ github.event.client_payload.repo_url }}
      OWNER:      ${{ github.event.client_payload.owner }}
      REPO:       ${{ github.event.client_payload.repo }}
      BRANCH:     ${{ github.event.client_payload.branch || 'main' }}
      TECH:       ${{ github.event.client_payload.technology }}
      CORR:       ${{ github.event.client_payload.correlation_id }}
      REPORT_PATH: ${{ github.event.client_payload.report_path }}

    steps:
      - name: Checkout orchestrator repo
        uses: actions/checkout@v4

      - name: Echo inputs
        run: |
          echo "TECH=$TECH"
          echo "REPO_URL=$REPO_URL"
          echo "BRANCH=$BRANCH"
          echo "REPORT_PATH=$REPORT_PATH"

      # ---------- Clone target repo (supports private via GH_PAT) ----------
      - name: Detect GH_PAT
        id: detect-pat
        env:
          GH_PAT: ${{ secrets.GH_PAT }}
        run: |
          if [ -n "${GH_PAT}" ]; then
            echo "USE_PAT=true" >> "$GITHUB_ENV"
          else
            echo "USE_PAT=false" >> "$GITHUB_ENV"
          fi

      - name: Clone (public)
        if: ${{ env.USE_PAT == 'false' }}
        run: |
          set -e
          echo "Cloning public repo: $REPO_URL ($BRANCH)"
          git clone --depth 1 --branch "$BRANCH" "$REPO_URL" target

      - name: Clone (private via PAT)
        if: ${{ env.USE_PAT == 'true' }}
        run: |
          set -e
          STRIPPED="${REPO_URL#https://}"
          URL_AUTH="https://${{ secrets.GH_PAT }}@${STRIPPED}"
          echo "Cloning private repo (masked URL) on branch $BRANCH"
          git clone --depth 1 --branch "$BRANCH" "$URL_AUTH" target

      # ---------- Optional config overlay per technology ----------
      - name: Overlay config pack
        run: |
          set -e
          TECH_LOWER=$(echo "$TECH" | tr '[:upper:]' '[:lower:]')
          SRC="configs/$TECH_LOWER"
          if [ -d "$SRC" ]; then
            echo "Overlaying $SRC -> target/"
            rsync -a --exclude 'tsconfig.template.json' "$SRC"/ target/
            if [ -f "$SRC/tsconfig.template.json" ] && git -C target ls-files '*.ts' '*.tsx' | grep -q .; then
              cp "$SRC/tsconfig.template.json" target/tsconfig.json
            fi
          else
            echo "No overlay for $TECH (optional)."
          fi

      # ---------- Toolchains ----------
      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Setup .NET
        if: ${{ env.TECH == 'DotNet' }}
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: '8.0.x'

      # =========================================================
      # ================  SALESFORCE (PMD)  =====================
      # =========================================================
      - name: Salesforce • Setup Java
        if: ${{ env.TECH == 'Salesforce' }}
        uses: actions/setup-java@v4
        with:
          distribution: 'temurin'
          java-version: '17'

      - name: Salesforce • Download PMD
        if: ${{ env.TECH == 'Salesforce' }}
        run: |
          set -e
          PMD_VER=6.55.0
          curl -L "https://github.com/pmd/pmd/releases/download/pmd_releases/${PMD_VER}/pmd-bin-${PMD_VER}.zip" -o pmd.zip
          sudo apt-get update -y
          sudo apt-get install -y unzip
          unzip -q pmd.zip
          mv "pmd-bin-${PMD_VER}" pmd
          ls -la pmd/bin

      - name: Salesforce • Full scan (Apex) → CSV
        if: ${{ env.TECH == 'Salesforce' }}
        working-directory: target
        run: |
          set -e
          mkdir -p ../out

          ROOT="force-app"
          [ -d "force-app" ] || ROOT="src"
          [ -d "$ROOT" ] || ROOT="."

          echo "Scanning Apex under: $ROOT"
          echo "Apex class files found:"
          git ls-files "$ROOT/**/*.cls" | wc -l || true

          ../../pmd/bin/run.sh pmd \
            -d "$ROOT" \
            -f csv \
            -R category/apex/bestpractices.xml,category/apex/design.xml,category/apex/errorprone.xml,category/apex/performance.xml,category/apex/security.xml \
            > ../out/pmd.csv || true

          echo "==== PMD CSV head ===="
          head -n 5 ../out/pmd.csv || true

          if [ ! -s ../out/pmd.csv ]; then
            echo "Problem,Package,File,Priority,Line,Description,Rule set,Rule" > ../out/pmd.csv
          fi

      # =========================================================
      # =====================   .NET   ==========================
      # =========================================================
      - name: .NET • Restore / format / build
        if: ${{ env.TECH == 'DotNet' }}
        working-directory: target
        run: |
          set -e
          dotnet tool install -g dotnet-format
          export PATH="$HOME/.dotnet/tools:$PATH"

          TARGET=$( (ls *.sln 2>/dev/null || true; ls *.csproj 2>/dev/null || true) | head -n 1 )
          if [ -z "$TARGET" ]; then TARGET=$(git ls-files "*.csproj" | head -n 1); fi
          if [ -z "$TARGET" ]; then
            echo "No .sln or .csproj found; writing empty outputs."
            mkdir -p ../out; echo "[]" > ../out/dotnet-format.json; : > ../out/build_output.txt; exit 0
          fi
          echo "Using target: $TARGET"

          dotnet restore "$TARGET" || true

          dotnet format "$TARGET" --verify-no-changes --report ../out/dotnet-format.json --report-format json || true

          dotnet build "$TARGET" --no-incremental -v:normal > ../out/build_output.txt || true

      # =========================================================
      # ====================  PYTHON  ===========================
      # =========================================================
      - name: Python • Install linters
        if: ${{ env.TECH == 'Python' }}
        run: |
          python -m pip install --upgrade pip
          pip install bandit pylint flake8 flake8-json

      - name: Python • Scan
        if: ${{ env.TECH == 'Python' }}
        working-directory: target
        run: |
          set -e
          mkdir -p ../out
          bandit -r . -f json -o ../out/bandit.json || true
          find . -name "*.py" > ../out/files.txt
          if [ -s ../out/files.txt ]; then
            pylint $(cat ../out/files.txt) --output-format=json > ../out/pylint.json || true
          else
            echo "[]" > ../out/pylint.json
          fi
          flake8 . --format=json --output-file=../out/flake8.json || true

      # =========================================================
      # =====================  REACT  ===========================
      # =========================================================
      - name: React • Install deps
        if: ${{ env.TECH == 'React' }}
        working-directory: target
        run: |
          npm ci || npm install

      - name: React • ESLint / tsc / audit
        if: ${{ env.TECH == 'React' }}
        working-directory: target
        run: |
          set -e
          mkdir -p ../out
          npx eslint . --ext .js,.jsx,.ts,.tsx -f json -o ../out/eslint.json || true
          if find . -name "tsconfig*.json" -type f | grep -q .; then
            npx tsc --noEmit > ../out/tsc-output.txt 2>&1 || true
          fi
          npm audit --json > ../out/audit.json || true

      # =========================================================
      # ==================  Normalize → CSV  ====================
      # =========================================================
      - name: Normalize to CSV
        run: |
          python - << 'PY'
          import os, json, csv, re
          rows=[["Tool","File","Line","Severity","Rule","Message"]]
          out="out/normalized.csv"
          os.makedirs("out", exist_ok=True)
          def add(tool,f,l,s,r,m): rows.append([tool,f or "",str(l or ""),str(s or ""),str(r or ""), (m or "").replace("\n"," ").strip()])

          # ---- Salesforce PMD CSV ----
          p="out/pmd.csv"
          if os.path.exists(p) and os.path.getsize(p)>0:
              try:
                  with open(p,newline="",encoding="utf-8",errors="ignore") as f:
                      r=csv.DictReader(f)
                      # PMD CSV headers: Problem,Package,File,Priority,Line,Description,Rule set,Rule
                      for d in r:
                          add("PMD", d.get("File"), d.get("Line"), d.get("Priority"), d.get("Rule"), d.get("Description"))
              except Exception as e:
                  print("PMD parse error:", e)

          # ---- .NET dotnet-format JSON ----
          p="out/dotnet-format.json"
          if os.path.exists(p) and os.path.getsize(p)>0:
              try:
                  data=json.load(open(p,encoding="utf-8"))
              except Exception as e:
                  data=None; print("dotnet-format parse error:", e)

              def field(d,*names,default=None):
                  for n in names:
                      if isinstance(d,dict) and n in d: return d.get(n)
                  return default
              def add_diag(v):
                  add(".NET",
                      field(v,"FilePath","file","Document"),
                      field(v,"LineNumber","line","StartLine"),
                      field(v,"Severity","severity","Category"),
                      field(v,"RuleId","id","DiagnosticId","rule"),
                      field(v,"Message","message","Title"))

              if isinstance(data,dict):
                  for v in (data.get("Diagnostics") or data.get("violations") or data.get("results") or []):
                      add_diag(v)
              elif isinstance(data,list):
                  for v in data: add_diag(v)

          # ---- .NET build warnings/errors (text) ----
          p="out/build_output.txt"
          if os.path.exists(p) and os.path.getsize(p)>0:
              rx=re.compile(r'(.+\.cs)\((\d+),\d+\): (warning|error) (\w+): (.+?) \[')
              for line in open(p,encoding="utf-8",errors="ignore"):
                  m=rx.search(line)
                  if m:
                      file,l,sev,rule,msg=m.groups()
                      add("dotnet-build", file, l, sev.capitalize(), rule, msg)

          # ---- Python ----
          p="out/bandit.json"
          if os.path.exists(p) and os.path.getsize(p)>0:
              data=json.load(open(p,encoding="utf-8"))
              for r in data.get("results",[]):
                  add("Bandit", r.get("filename"), r.get("line_number"), r.get("issue_severity"), r.get("test_id"), r.get("issue_text"))
          p="out/pylint.json"
          if os.path.exists(p) and os.path.getsize(p)>0:
              data=json.load(open(p,encoding="utf-8"))
              if isinstance(data,list):
                  for it in data:
                      sev = (it.get("type") or "").capitalize()
                      add("Pylint", it.get("path"), it.get("line"), sev, it.get("message-id"), it.get("message"))
          p="out/flake8.json"
          if os.path.exists(p) and os.path.getsize(p)>0:
              data=json.load(open(p,encoding="utf-8"))
              for file, issues in data.items():
                  for i in issues:
                      add("Flake8", file, i.get("line_number"), i.get("code"), i.get("code"), i.get("text"))

          # ---- React ----
          p="out/eslint.json"
          if os.path.exists(p) and os.path.getsize(p)>0:
              data=json.load(open(p,encoding="utf-8"))
              if isinstance(data,dict): data=[data]
              for f in data:
                  fn=f.get("filePath")
                  for m in f.get("messages",[]):
                      sev="Error" if m.get("severity")==2 else "Warning"
                      add("ESLint", fn, m.get("line"), sev, m.get("ruleId"), m.get("message"))

          p="out/tsc-output.txt"
          if os.path.exists(p) and os.path.getsize(p)>0:
              rx=re.compile(r"(.+\.(?:ts|tsx|js|jsx))\((\d+),\d+\): (error|warning) (TS\d+): (.+)")
              for line in open(p,encoding="utf-8",errors="ignore"):
                  m=rx.search(line)
                  if m:
                      file,l,sev,code,msg=m.groups()
                      add("tsc", file, l, sev.capitalize(), code, msg)

          p="out/audit.json"
          if os.path.exists(p) and os.path.getsize(p)>0:
              data=json.load(open(p,encoding="utf-8"))
              for pkg,v in (data.get("vulnerabilities") or {}).items():
                  for item in v.get("via",[]):
                      if isinstance(item,dict):
                          add("npm-audit", pkg, "", v.get("severity"), item.get("name") or item.get("title"), item.get("title"))

          with open(out,"w",newline="",encoding="utf-8") as f:
              csv.writer(f).writerows(rows)
          print("Wrote", out, "rows:", len(rows)-1)
          PY

      # ---------- Commit normalized CSV into orchestrator repo ----------
      - name: Commit report into orchestrator
        run: |
          set -e
          mkdir -p "$(dirname "$REPORT_PATH")"
          cp out/normalized.csv "$REPORT_PATH"
          git config user.name "orchestrator-bot"
          git config user.email "orchestrator@example.com"
          git add "$REPORT_PATH"
          git commit -m "Scan report: $OWNER/$REPO ($TECH) • $CORR" || echo "Nothing to commit"
          git push

      # Optional: artifact for manual download from the Actions run UI 
      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: report-${{ env.CORR }}
          path: out/normalized.csv
